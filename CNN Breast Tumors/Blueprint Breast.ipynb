{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aedd5f3-c4e3-4fca-ba55-02f717b8d363",
   "metadata": {},
   "source": [
    "# Use A CNN To Process The Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5543e1-28b2-4053-b732-9099e997bc44",
   "metadata": {},
   "source": [
    "### Goal: Build a CNN to Determine Predict Malignancy Of Breast Tissues From Patient Slides "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac1905-7938-4fe2-bf11-af3d21ef16f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Requirements \n",
    "\n",
    "### Datasets:\n",
    "Kaggle Data Set: BreaKHis 400x\n",
    "URL: https://www.kaggle.com/datasets/forderation/breakhis-400x\n",
    "\n",
    "### Python:\n",
    "Python3 (3.11.5)\n",
    "\n",
    "### Modules:\n",
    "TensorFlow (2.14.0)\n",
    "\n",
    "Numpy (1.26.1)\n",
    "\n",
    "Matplotlib (3.8.0)\n",
    "\n",
    "Scikit Learn (1.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e8a65c-3607-43fd-959d-f6dce90444d1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.5\n",
      "Tensor Flow: 2.14.0\n",
      "Numpy: 1.26.1\n",
      "Matplotlib: 3.8.0\n",
      "Sklearn: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import sklearn\n",
    "print('Python:',  python_version())\n",
    "print (\"Tensor Flow:\", tf.__version__)\n",
    "print (\"Numpy:\", np.__version__)\n",
    "print (\"Matplotlib:\", matplotlib.__version__)\n",
    "print (\"Sklearn:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e167b9f-9b63-447b-93e4-6c186c961d90",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60",
    "tags": []
   },
   "source": [
    "## Part 1 - Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d9a63d-9f1e-4cc7-ad68-cd8ee1b4692a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc46cb-853f-48ef-a722-987d6d17a9e1",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE",
    "tags": []
   },
   "source": [
    "## Part 2 - Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabc5dbf-1061-4af2-8aa2-14fe298936dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = 'P:/Portfolio Sets/CNN Breast Tumors/BreaKHis 400X/train' \n",
    "#watch the direction of slashes, '\\' will confuse python use '/' or '\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b403a6-4e64-4d96-8770-c2b9528a4ebe",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG",
    "tags": []
   },
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fc8d8e-685c-4cd7-a8a2-2656a89935c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1148 files belonging to 2 classes.\n",
      "Using 919 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path, #file path\n",
    "    labels = 'inferred',  #Automatically infer labels from directory structure (folder names)\n",
    "    label_mode = 'categorical',  #Categorical/int/etc.\n",
    "    color_mode='rgb', #Sets the color of the images rgb/grayscale\n",
    "    image_size = (64, 64), #Image size for resizing\n",
    "    batch_size = 32,  #Batch size(number of images per batch)\n",
    "    shuffle = True, #Shuffles the images prior to selection for batch designation (True - default) \n",
    "    # False enables consistency for verifying image augmentation, but should be True when deploying\n",
    "    seed = 100, #Same random selection instance each time, required for splitting into training and validation sets\n",
    "    validation_split = 0.2,  #Dataset Split for training and validation sets\n",
    "    subset = 'training')  #Specify training/validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908430f-f0c2-4c38-a6ad-6cd6ba76f7e2",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e9b3b3-6116-45b4-93f3-89aef8386947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (567999244.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    shuffle = True\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path, \n",
    "    labels = 'inferred',\n",
    "    label_mode ='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    "    seed = 100,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50159259-08a4-4358-89fd-9340bf86347e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c468b92-1dad-49c8-9288-44385858df5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'P:/Portfolio Sets/CNN Breast Tumors/BreaKHis 400X/test', #file path\n",
    "    labels = 'inferred',  #Automatically infer labels from directory structure (folder names)\n",
    "    label_mode = 'categorical',  #Categorical/int/etc.\n",
    "    color_mode='rgb', #Sets the color of the images rgb/grayscale\n",
    "    image_size = (64, 64), #Image size for resizing\n",
    "    batch_size = 9,  #Number must be included if the CNN model has a batch size shapes need to match (Batch, height, width, rgb)\n",
    "    shuffle = False,\n",
    "    validation_split = None,  #Dataset Split for training and validation sets\n",
    "    subset = None)  #Specify training/validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98735e-ddc8-4126-b9fb-27020c7d63bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TensorFlow Datatype\n",
    "TensorFlow Data is a tuple of tuple datatype\n",
    "\n",
    "It consists of TensorSpec which will contain either image or label information. This example contains:\n",
    "\n",
    "1) Image data (BatchSize, Height, Width, RGB/BW) \n",
    "    \n",
    "    a) BatchSize = Number of data instance per Tensor\n",
    "    \n",
    "    b) Height = Pixel Height\n",
    "    \n",
    "    c) Width = Pixel Width\n",
    "    \n",
    "    d) RGB/BW = Color Channels (RGB = 3, BW = 1)\n",
    "    \n",
    "Notes: Iterating through the image data will give call height, row, color channels as a multidimensional array. \n",
    "\n",
    "Example: (5, 4, 3) image formats to 5 columns(height) with 4 rows(width) but at each position 3 colum values for each RGB channel . \n",
    "\n",
    "2) Label Data (BatchSize, ClassLabels) \n",
    "    \n",
    "    a) BatchSize = Number of data instance per Tensor\n",
    "    \n",
    "    b) ClassLabels = Number of classes set (\"inferred\" or specified upon loading data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ba87d-ab9c-4c68-adfb-2e10c040f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.element_spec)\n",
    "print(\"+++++++++++++++++++++++++++++\")\n",
    "print(train_dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cc59d-4a2f-4f40-b9c6-01c016d576a0",
   "metadata": {},
   "source": [
    "### Iterating with Tensorflow Data\n",
    "\n",
    "During an interative process (For loop/ While), you must be aware of key processes/best practices\n",
    "\n",
    "1) If shuffle = true during data loading, recalling an iterative function of the dataset will reshuffle the data each time unless you reload the data fresh.    \n",
    "\n",
    "2) No Batch Index is stored in the TF data. A batch index is useful for perform operations on a specific batch. To generate a makeshift one use Python's enumerate function.\n",
    "\n",
    "3) Ensure to call all tensorspecs of the TF data in the function to avoid confusion\n",
    "\n",
    "##### Examples of Proper Iterative Function:\n",
    "\n",
    "1) for images, labels in TF_dataset:\n",
    "\n",
    "2) for i, (images, labels) in enumerate(TD_dataset): \n",
    "\n",
    "Here, Enumerate returns a tuple containing (batch count, value = (images, labels))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecce99-1c28-4c80-8df7-a188fcc9155a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Optional) Image Verification\n",
    "Image Verification with TensorFlow datasets, requires iteration functions (see above for proper use)\n",
    "\n",
    "Ensure shuffle = false to be able to verify datasets. \n",
    "\n",
    "Note: Training/Validation datasets should be swapped back to shuffle = True prior to model training "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4282556-524c-4d13-a510-74dfb464ed97",
   "metadata": {},
   "source": [
    "# For all image data\n",
    "for images, labels in test_dataset:\n",
    "    plt.figure(figsize = (4, 4))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(3, 3, i+1) # (nrows, ncols, index)\n",
    "        #required conversion of tensor data -> numpy array for compatibility with matplotlib \n",
    "        plt.imshow(images[i].numpy()) #use .astype(\"uint8\") here if not yet scaled. It will make the figure plottable\n",
    "        if np.array_equal(labels[i].numpy(), np.array([1, 0])):\n",
    "            plt.title(\"Benign\")\n",
    "        else:\n",
    "            plt.title(\"Malignant\")\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "    plt.tight_layout() # No overlap of graphs\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9dbb9fe-f474-47a3-bed3-73f099c867e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# For a specific batch image set\n",
    "for i, (images, labels) in enumerate(train_dataset): #enumerate will give a tuple that consist of a count and the corresponding value\n",
    "    #here i = count index on the batch, value = the_dataset values which is a tuple containing images data and labels classification\n",
    "    if i == 0: #sets the index of the batch selected\n",
    "        plt.figure(figsize = (10, 10))\n",
    "        for p in range(len(images)): #iterate through the count of images to plot\n",
    "            plt.subplot(4, 8, p+1) #(nrows, ncols, index)\n",
    "            #required conversion of tensor data -> numpy array for compatibility with matplotlib\n",
    "            plt.imshow(images[p].numpy().astype(\"uint8\")) #use .astype(\"uint8\") here because it not yet scaled. It will make the figure plottable\n",
    "            if np.array_equal(labels[i].numpy(), np.array([1, 0])):\n",
    "                plt.title(\"Benign\")\n",
    "            else:\n",
    "                plt.title(\"Malignant\")\n",
    "            plt.axis('off')  # Turn off axis labels\n",
    "        plt.tight_layout() #No overlap of graphs\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe4038cd-39ec-4781-8d56-a8a87facce4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# For single image in the tensor flow dataset\n",
    "for i, (images, labels) in enumerate(test_dataset): #enumerate will give a tuple that consist of a count and the corresponding value\n",
    "    #here i = batch, value = the_dataset values which is a tuple containing images data and labels classification\n",
    "    if i == 0: #sets the batch\n",
    "        plt.figure(figsize = (2, 2))\n",
    "        plt.imshow(images[8].numpy()) # uint8 ciritical for proper display if unscaled to 1/255 (Very IMPORTANT)\n",
    "        if np.array_equal(labels[i].numpy(), np.array([1, 0])):\n",
    "            plt.title(\"Benign\")\n",
    "        else:\n",
    "            plt.title(\"Malignant\")\n",
    "        plt.axis('off')  # Turn off axis labels\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82763206-eb8b-4eb5-8258-10af1034a76f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 - Preprocessing/Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ca1b2-ddd7-47ce-9914-8658c1faff00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Augmentation\n",
    "\n",
    "Augmentation avoids overfitting the training data during model training. These include geometric transformations, rotate images, zoom in/out, flip images, etc. \n",
    "\n",
    "Augmentation can be applied to the training dataset at 1 of 2 different points\n",
    "\n",
    "Option 1) The Preprocessing Step prior to CNN model (Easier Modularity and Maintenance) (Done Here)\n",
    "\n",
    "Option 2) Included in the actual CNN model (Easier Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b131c86-3fd2-4006-8809-ea93688be4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation\n",
    "\n",
    "Augmentation = tf.keras.models.Sequential([   \n",
    "    Rescaling(1.0 / 255), #Rescales the pixel values so that all numbers are between 0 and 1\n",
    "    RandomFlip(\"horizontal\"), #Randomly Flips image\n",
    "    RandomRotation(factor=0.2) #Rotates Images\n",
    "])\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (Augmentation(x, training = True), y))\n",
    "# (x, y) = (images, image labels), training = flag to indicate augmentation should be applied during training\n",
    "# lambda as always is an anonymous function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962f0f9-9543-4377-8758-ad6533299123",
   "metadata": {},
   "source": [
    "### Verifying Image Augmentation\n",
    "NOTE: To verify Image Augmentation is faithful, the training set:\n",
    "\n",
    "##### shuffle = false \n",
    "\n",
    "when initial loading of dataset. Otherwise, images will be reshuffled and you will get a different image output when running the verification; this is an inherent property of tensorflow.\n",
    "\n",
    "Once verification is confirmed reload the training set with:\n",
    "\n",
    "##### shuffle = true"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4710dd10-6d80-4b0b-8c75-ea977672c4b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#prior to running the code ensure shuffle = false during the data upload\n",
    "for i, (images, labels) in enumerate(train_dataset): #enumerate will give a tuple that consist of a count and the corresponding value\n",
    "    #here i = batch, value = the_dataset values which is a tuple containing images data and labels classification\n",
    "    if i == 0: #sets the batch\n",
    "        plt.figure(figsize = (10, 10))\n",
    "        for p in range(len(images)): #iterate through the count of images to plot\n",
    "            plt.subplot(4, 8, p+1) #(nrows, ncols, index)\n",
    "            #required conversion of tensor data -> numpy array for compatibility with matplotlib\n",
    "            plt.imshow(images[p].numpy()) #do not use .astype(\"uint8\") here because it was 1/255 scaled. It will make the figure uninterpretable\n",
    "            plt.title(f\"Class: {labels[i].numpy()}\")\n",
    "            plt.axis('off')  # Turn off axis labels\n",
    "        plt.tight_layout() #No overlap of graphs\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5c63c-aa50-4d87-9345-820a9c8c1108",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rescaling Validation and Test DataSet\n",
    "Validation and Test Datasets should be rescaled to match Training Dataset for model fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c5174-23d8-4a2d-88de-a5cf96c27273",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rescale = tf.keras.Sequential([Rescaling(1.0 / 255)])\n",
    "validation_dataset = validation_dataset.map(lambda x, y: (Rescale(x, training = False), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (Rescale(x, training = False), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118018fc-7210-401b-a6c5-2b8ae9f08e99",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B",
    "tags": []
   },
   "source": [
    "## Part 3 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd081158-0bba-4a4d-97c4-db9ae2a81636",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50dfb24-d9b3-462c-b893-dc06238aee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c48ac-7dcd-41e1-a04b-1434219e5c65",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0dccf-f64a-45cd-8c14-9df2b6ef3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Layer\n",
    "cnn.add(tf.keras.layers.Conv2D( #add function applies new layer\n",
    "    filters = 32, # Number of features\n",
    "    kernel_size = 3, # Dimensions of feature detector (single digit is squared (X -> 3 x 3) or paired acceptable (X, Y -> (X x Y)  \n",
    "    activation = 'relu', # Activation type \n",
    "    input_shape = (64, 64, 3))) # Tuple that selects image properties (batch size(optional), size, size, 3(RGB) or 1(B&W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c68bb1-810c-4f6c-b9a9-ca0a1fef1d32",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8943ce-c130-4caf-9138-f65c19a33071",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2, # frame size of the pool (single digit is squared (X -> 3 x 3) or paired acceptable (X, Y -> (X x Y)  \n",
    "    strides = 2, # pixels the frame will move over when pooling (single digit is squared (X -> 3 x 3) or paired acceptable (X, Y -> (X x Y)\n",
    "    padding = 'valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb32e7-9daf-4bd4-886d-6ba42a75aa8b",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### (Optional) Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "195d3dcd-241c-4bf8-981e-df2b7ad71b86",
   "metadata": {},
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2,padding='valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc65f8-24e7-471e-9ccc-e0cf8182465d",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bdeb8-c866-44e3-88e4-52f2ad2714c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening - Converts the data into 1D array\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "#automatically flattens prior to CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163ac3e-2e3b-4ec7-b753-634a66c9d01b",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208cc69-2383-4dc8-ad7b-28fbdab489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the Layers\n",
    "cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "# units = the number of neurons for this layer (higher usually means more accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eaf7dc-8f5a-42a7-84b8-4025d4c5751a",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a4c4d-2678-43c1-a78f-2f0607dc291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer - Final Layer To Predict Classification\n",
    "cnn.add(tf.keras.layers.Dense(units = 2, activation='softmax'))\n",
    "# set the number of neurons for final classification output, binary (units = 1) vs for multiclass/categorical (units = number of categories)\n",
    "#activation will be sigmoid for binary (units = 1), for multiclass(categorical) could softmax"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e22119bd-c64e-4b31-b819-2ed741f47a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "shortened summarized version of Steps 1-5\n",
    " cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(image_height, image_width, channels)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(), #last layer before moving data to neural network    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d680f9-8de3-466b-95ec-c81bdde53675",
   "metadata": {},
   "source": [
    "### Step 6 - Compile The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d03b81-600e-4d29-8ea4-b66c13886d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#compiles the cnn to the optimizer and loss function using accuracy as the metric\n",
    "\n",
    "#Generate the model summary\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdc0c5-9abb-46e3-9a12-77346be8c5bd",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl",
    "tags": []
   },
   "source": [
    "## Part 4 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26790505-dbe8-4173-a125-28aff72107f2",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h",
    "tags": []
   },
   "source": [
    "### Training Model on Training Set and Evaluating on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ed537-4e50-4d8e-bd9e-67c583e5c31b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.fit(x = train_dataset, validation_data = validation_dataset, epochs = 20)\n",
    "#trains the cnn\n",
    "\n",
    "#loss and accuracy = training data\n",
    "#val_loss and val_accuracy = validation data\n",
    "#lower loss is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69deaf6b-6fc5-49a0-bf29-8debb54d818f",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z",
    "tags": []
   },
   "source": [
    "## Part 5 - Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45587751-9bf6-4fe2-a5ca-de339b8279d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PredictProb = cnn.predict(test_dataset)\n",
    "print(PredictProb) #Provides an array where the numbers indicate the probability of it being that particular class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb1cef-e0f2-43a7-b713-3267e146df92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PredictClass = (PredictProb >= 0.5).astype(int) #set the threshold as 0.5\n",
    "PredictClass[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a50e82-472a-4fbe-954d-ac9be914d80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    if PredictClass[i][0] == 1: #result 1st slot as batch dimension so we run result[0] to enter the batch the next [0] selects the element in the batch(the single dog image) \n",
    "        prediction = 'benign'\n",
    "    elif PredictClass[i][1] == 1:    \n",
    "        prediction = 'malignant'\n",
    "    else:\n",
    "        prediction = 'Error'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a420a-9db0-47b0-8db2-8d3626929716",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy Score\n",
    "Confusion Matrix can be run on Numpy Arrays and should be one hot encoded prior to running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2600f6-98e7-40fc-a038-f181bf659338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert the Tensorflow Test Dataset classlabels into a Numpy Array \n",
    "TrueClass = np.empty((0, 2)) # Initialize an empty NumPy array with no rows and 2 columns (no data entry yet)\n",
    "print (TrueClass)\n",
    "print ('Shape =', TrueClass.shape)\n",
    "for images, labels in test_dataset:\n",
    "    nlab = labels.numpy().astype(int)  # Convert labels to a NumPy array ain an integer format\n",
    "    TrueClass = np.concatenate((TrueClass, nlab), axis=0) #concatenates all the batches joining batches based on columns\n",
    "\n",
    "print ('+++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print (TrueClass)\n",
    "print ('Shape = ', TrueClass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7b7a1-ae33-4953-bd4c-8ebd91fad9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run the confusion matrix and accuracy score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm_True = np.argmax(TrueClass, axis= 1)  \n",
    "cm_Predict = np.argmax(PredictClass, axis = 1) #returns index value\n",
    "#axis = 0 returns the row index that has the highest value in a column), axis = 1 returns the col index for the highest value in a row \n",
    "\n",
    "\n",
    "print(confusion_matrix(cm_True, cm_Predict))\n",
    "print(accuracy_score(cm_True, cm_Predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f174233-abfb-42f7-ae92-8dea37bb405b",
   "metadata": {},
   "source": [
    "### Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723231d6-90b2-4999-a58a-03d46fe71b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test a single image from user selection\n",
    "test_image = tf.keras.utils.load_img('P:/Portfolio Sets/CNN Breast Tumors/BreaKHis 400X/test/malignant/SOB_M_DC-14-10926-400-005.png', target_size = (64, 64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image) #changes to an array so the cnn model can analyze\n",
    "test_image /= 255\n",
    "plt.figure(figsize = (2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0) #adds an extra dimension to match the batch dimension within the CNN model\n",
    "#dimension of batch is added as the 1st dimension \n",
    "\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "print (result)\n",
    "\n",
    "#Class label based on the train_dataset.class_names [benign, malignant]\n",
    "result = (result >= 0.5).astype(int)\n",
    "if np.all(result == np.array([1, 0])):\n",
    "    print('Benign')\n",
    "elif np.all(result == np.array([0, 1])):\n",
    "    print('Malignant')\n",
    "else:\n",
    "    print('Error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
